{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH02ofmq5gS6"
      },
      "source": [
        "#**This Notebook Shows How to use Agents to Interact with Pandas DataFrame**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7X1Fq1q6jRw"
      },
      "source": [
        "#**In LangChain, the Agent can access many dataframes at once**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zotWGw4D6vO9"
      },
      "source": [
        "#**Step 01: Install All the Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjduxL3B5UCP",
        "outputId": "e59efb20-2f50-463b-c1d5-39dec6161a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (3.1.0)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.4.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: google-generativeai in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (0.8.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Using cached langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.4.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.9.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-google-genai) (0.9.0)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.40.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
            "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-experimental) (0.3.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.4.1)\n",
            "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.1.0)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-python-client in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\anilk\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Using cached langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "Installing collected packages: langchain-core, google-ai-generativelanguage, langchain-google-genai, langchain-experimental\n",
            "\n",
            "  Attempting uninstall: langchain-core\n",
            "\n",
            "    Found existing installation: langchain-core 1.1.0\n",
            "\n",
            "    Uninstalling langchain-core-1.1.0:\n",
            "\n",
            "      Successfully uninstalled langchain-core-1.1.0\n",
            "\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "    Found existing installation: google-ai-generativelanguage 0.9.0\n",
            "   ---------------------------------------- 0/4 [langchain-core]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "    Uninstalling google-ai-generativelanguage-0.9.0:\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.9.0\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "  Attempting uninstall: langchain-google-genai\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "    Found existing installation: langchain-google-genai 3.1.0\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "    Uninstalling langchain-google-genai-3.1.0:\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "      Successfully uninstalled langchain-google-genai-3.1.0\n",
            "   ---------- ----------------------------- 1/4 [google-ai-generativelanguage]\n",
            "   -------------------- ------------------- 2/4 [langchain-google-genai]\n",
            "   -------------------- ------------------- 2/4 [langchain-google-genai]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ------------------------------ --------- 3/4 [langchain-experimental]\n",
            "   ---------------------------------------- 4/4 [langchain-experimental]\n",
            "\n",
            "Successfully installed google-ai-generativelanguage-0.6.15 langchain-core-0.3.80 langchain-experimental-0.3.4 langchain-google-genai-2.0.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.80 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\n",
            "langgraph-prebuilt 1.0.4 requires langchain-core>=1.0.0, but you have langchain-core 0.3.80 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#!pip install langchain\n",
        "#!pip install watermark\n",
        "#!pip install openai\n",
        "!pip install langchain langchain-google-genai langchain-experimental google-generativeai pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0s5kTxf7VCm"
      },
      "source": [
        "#**Step 02: Import All The Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T7IioE_66-N2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wRkcMjDB78Br"
      },
      "outputs": [],
      "source": [
        "#from langchain.agents import create_pandas_dataframe_agent\n",
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "#from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3jGXIR77nWQ"
      },
      "source": [
        "#**Step 03: Setup the Environment**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DJlywphB7Jyx"
      },
      "outputs": [],
      "source": [
        "#os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDLgBerlKVS4jWuoO2uDUDgR2hg-VAyaQs\"\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDLgBerlKVS4jWuoO2uDUDgR2hg-VAyaQs\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y3o6s0a80Zw"
      },
      "source": [
        "#**Step 04: Visualize the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "-592m0MV73EJ",
        "outputId": "b9255cba-29ac-4a0a-f833-873f7bbaf074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(891, 12)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#url = \"https://raw.githubusercontent.com/sudarshan-koirala/Logistic-Regression-for-Titanic-Dataset/master/Train_Titanic.csv\"\n",
        "df=pd.read_csv(r'D:\\Data Science Daily Updates\\Senapthi_calss_Notes\\GEN AI NOTES\\LangChian Practicals\\Langchain Agents\\titanic dataset.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IY8w4JO9aVc"
      },
      "source": [
        "#**Step 05: Single DataFrame Example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNe57hcF-wan"
      },
      "source": [
        "#**Agent can interact with Single DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_dmmbSRj_C6_"
      },
      "outputs": [],
      "source": [
        "#llm=OpenAI()\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: tabulate\n",
            "Successfully installed tabulate-0.9.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install tabulate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anilk\\AppData\\Local\\Temp\\ipykernel_11640\\4037234945.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  agent.run(\"How many rows are in the dataset?\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'df.shape[0]'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m891\u001b[0m\u001b[32;1m\u001b[1;3mThere are 891 rows in the dataset.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': \"len(df[df['SibSp'] > 3])\"}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m30\u001b[0m\u001b[32;1m\u001b[1;3mThere are 30 passengers with more than 3 siblings.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'There are 30 passengers with more than 3 siblings.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#agent=create_pandas_dataframe_agent(llm, df, verbose=True)\n",
        "agent = create_pandas_dataframe_agent(llm, df, verbose=True, agent_type=\"tool-calling\", allow_dangerous_code=True\n",
        ")\n",
        "\n",
        "agent.run(\"How many rows are in the dataset?\")\n",
        "agent.run(\"How many passengers have more than 3 siblings?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "MlHrvWqe_NcF",
        "outputId": "aaf865f5-e818-4865-c8a8-2af41c036d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'len(df)'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m891\u001b[0m\u001b[32;1m\u001b[1;3mThere are 891 rows in the dataframe.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'There are 891 rows in the dataframe.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"How many rows are there\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "MynWTLaH_ZCC",
        "outputId": "4bdc7ada-c067-49ba-d682-da3275aaee63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': \"len(df[df['SibSp'] > 3])\"}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m30\u001b[0m\u001b[32;1m\u001b[1;3mThere are 30 people who have more than 3 siblings.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'There are 30 people who have more than 3 siblings.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"How many people have more than 3 siblings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So0M1eZF_iGZ"
      },
      "source": [
        "#**Step 06: Multi DataFrame Example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjJOixeA_pa1"
      },
      "source": [
        "#**Agent can also interact with Multiple DataFrames passed in a list**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qnpsxt0w_n3o",
        "outputId": "6eaafd8b-cb3f-4663-a9fd-abeee8f5f4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JRtvCp46_0Ux"
      },
      "outputs": [],
      "source": [
        "df1=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "z7RQ4BhM_0XW"
      },
      "outputs": [],
      "source": [
        "df1[\"Age\"] = df1[\"Age\"].fillna(df1[\"Age\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RX5EVDSB_0c5"
      },
      "outputs": [],
      "source": [
        "#agent=create_pandas_dataframe_agent(llm, [df, df1], verbose=True)\n",
        "agent = create_pandas_dataframe_agent(llm, [df,df1], verbose=True, agent_type=\"tool-calling\", allow_dangerous_code=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "8qW8HeOk_0fy",
        "outputId": "30335bda-f605-41f9-f69e-7ff05698d787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: We can use the `value_counts()` function to count the unique values in the age column, and then subtract one to remove the NaN value.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[\"Age\"].value_counts().shape[0]-1\u001b[0m\u001b[36;1m\u001b[1;3mNameError: name 'df' is not defined\u001b[0m\u001b[32;1m\u001b[1;3mWe need to specify which dataframe we are working with.\n",
            "Action: python_repl_ast\n",
            "Action Input: df1[\"Age\"].value_counts().shape[0]-1\u001b[0m\u001b[36;1m\u001b[1;3m87\u001b[0m\u001b[32;1m\u001b[1;3m87 rows in the age column are different.\n",
            "Final Answer: 87\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'87'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"How many rows in the age column are different\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "u60FO5PA_0iP"
      },
      "outputs": [],
      "source": [
        "df2=df1.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "oMwaMfn7AjeP"
      },
      "outputs": [],
      "source": [
        "df2[\"Age_Multiplied\"]=df1[\"Age\"] * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CYcPLbzGAjhP",
        "outputId": "9b3d9025-d3eb-4c11-982d-3167b6de0e72"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Age_Multiplied</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  Age_Multiplied  \n",
              "0      0         A/5 21171   7.2500   NaN        S            44.0  \n",
              "1      0          PC 17599  71.2833   C85        C            76.0  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S            52.0  \n",
              "3      0            113803  53.1000  C123        S            70.0  \n",
              "4      0            373450   8.0500   NaN        S            70.0  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zjzVpXHzAjkE"
      },
      "outputs": [],
      "source": [
        "#agent=create_pandas_dataframe_agent(llm, [df,df1, df2], verbose=True)\n",
        "agent = create_pandas_dataframe_agent(llm, [df,df1,df2], verbose=True, agent_type=\"tool-calling\", allow_dangerous_code=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "TWOnKkrUAjmp",
        "outputId": "8ea20e4f-8676-4dda-b39b-8d33099d42d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': '\\nprint(df1.shape[1])\\nprint(df2.shape[1])\\nprint(df3.shape[1])\\n'}`\n",
            "\n",
            "\n",
            "\u001b[0m12\n",
            "12\n",
            "\u001b[36;1m\u001b[1;3m13\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `python_repl_ast` with `{'query': 'print(df1.shape[1])\\nprint(df2.shape[1])\\nprint(df3.shape[1])'}`\n",
            "\n",
            "\n",
            "\u001b[0m12\n",
            "12\n",
            "\u001b[36;1m\u001b[1;3m13\n",
            "\u001b[0m\u001b[32;1m\u001b[1;3mYes, the number of columns is the same in all dataframes. They all have 13 columns.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Yes, the number of columns is the same in all dataframes. They all have 13 columns.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run(\"Are the number of columns same in all the dataframe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#LANGCHAIN, PANDAS, AGENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
